{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import utils.baseline_functions as base\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "os.chdir('/Users/jingyuanhu/Desktop/Research/Interpretable Opioid')\n",
    "SAMPLE = pd.read_csv('Data/PATIENT_TABLE.csv', delimiter = \",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple CART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = SAMPLE[['Gender', 'Age', 'Age_Gender', 'Num_presc',\n",
    "            'Total_days_supply', 'Avg_MME', 'Concurrent_opioid', 'Concurrent_benzo',\n",
    "            'Num_drug', 'Insurance_change', 'Codeine', 'Codeine_MME', 'Hydrocodone',\n",
    "            'Hydrocodone_MME', 'Oxycodone', 'Oxycodone_MME', 'Morphine',\n",
    "            'Morphine_MME', 'Hydromorphone', 'Hydromorphone_MME', 'Methadone',\n",
    "            'Methadone_MME', 'Fentanyl', 'Fentanyl_MME', 'Oxymorphone',\n",
    "            'Oxymorphone_MME', 'Medicaid', 'CommercialIns', 'Medicare',\n",
    "            'CashCredit', 'MilitaryIns', 'WorkersComp', 'Other', 'IndianNation',\n",
    "            'Change_Medicaid', 'Change_CommercialIns', 'Change_Medicare',\n",
    "            'Change_CashCredit', 'Change_MilitaryIns', 'Change_WorkersComp',\n",
    "            'Change_Other', 'Change_IndianNation']].values\n",
    "y = SAMPLE['Long_term_user'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 42, stratify = y)\n",
    "\n",
    "# Cross-validation\n",
    "# parameters = {'max_depth':[i for i in range(1,10)]}\n",
    "# parameters = {'min_impurity_decrease':[0, 1e-5, 1e-4, 1e-3, 1e-2]}\n",
    "# clf_decision_tree = GridSearchCV(tree.DecisionTreeClassifier(random_state = 42, class_weight='balanced'), parameters, cv=5)\n",
    "# clf_decision_tree.fit(X_train, y_train)\n",
    "# x_axis = [i for i in range(1,10)]\n",
    "# plt.plot(x_axis, clf_decision_tree.cv_results_['mean_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "clf_decision_tree = tree.DecisionTreeClassifier(max_depth = 5, random_state = 42, \n",
    "                                                class_weight='balanced', min_samples_leaf = 5,\n",
    "                                                min_impurity_decrease = 1e-5)\n",
    "clf_decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Plot\n",
    "fig, axe = plt.subplots(figsize=(40,10), dpi = 300)\n",
    "tree.plot_tree(clf_decision_tree, feature_names = ['Gender', 'Age', 'Age_Gender', 'Num_presc',\n",
    "                                                   'Total_days_supply', 'Avg_MME', 'Concurrent_opioid', 'Concurrent_benzo',\n",
    "                                                   'Num_drug', 'Insurance_change', 'Codeine', 'Codeine_MME', 'Hydrocodone',\n",
    "                                                   'Hydrocodone_MME', 'Oxycodone', 'Oxycodone_MME', 'Morphine',\n",
    "                                                   'Morphine_MME', 'Hydromorphone', 'Hydromorphone_MME', 'Methadone',\n",
    "                                                   'Methadone_MME', 'Fentanyl', 'Fentanyl_MME', 'Oxymorphone',\n",
    "                                                   'Oxymorphone_MME', 'Medicaid', 'CommercialIns', 'Medicare',\n",
    "                                                   'CashCredit', 'MilitaryIns', 'WorkersComp', 'Other', 'IndianNation',\n",
    "                                                   'Change_Medicaid', 'Change_CommercialIns', 'Change_Medicare',\n",
    "                                                   'Change_CashCredit', 'Change_MilitaryIns', 'Change_WorkersComp',\n",
    "                                                   'Change_Other', 'Change_IndianNation'], \\\n",
    "               class_names = ['short','long'], filled = True, rounded = True, ax = axe, fontsize=10)\n",
    "\n",
    "# fig.savefig('decisiontree_all.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# AUC\n",
    "y_pred_prob = clf_decision_tree.fit(X_train, y_train).predict_proba(X_test)[:,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_prob)\n",
    "p, r, _ = metrics.precision_recall_curve(y_test, y_pred_prob)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "pr_auc = metrics.auc(r, p)\n",
    "\n",
    "# PR\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "ax1.set_xlabel('Recall')\n",
    "ax1.set_ylabel('Precision')\n",
    "ax1.set_title('PR Curve')\n",
    "# ROC\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "ax2.set_xlabel('False Positive Rate')\n",
    "ax2.set_ylabel('True Positive Rate')\n",
    "ax2.set_title('ROC Curve')\n",
    "\n",
    "ax1.plot(r, p, label=\"AUC =\" + str(round(pr_auc, 4)))\n",
    "ax2.plot(fpr, tpr, label=\"AUC =\" + str(round(roc_auc, 4)))\n",
    "ax1.legend(loc='upper right')    \n",
    "ax2.legend(loc='lower right')\n",
    "# fig.savefig('pr_roc_all.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# higher F1 scores are generally better?\n",
    "y_pred = clf_decision_tree.predict(X_test)\n",
    "accuracy = clf_decision_tree.score(X_test, y_test)\n",
    "recall = metrics.recall_score(y_test, y_pred)\n",
    "precision = metrics.precision_score(y_test, y_pred)\n",
    "f1_score = metrics.fbeta_score(y_test, y_pred, beta = 1)\n",
    "f2_score = metrics.fbeta_score(y_test, y_pred, beta = 2)\n",
    "brier = metrics.brier_score_loss(y_test, y_pred)\n",
    "print(round(accuracy,4),round(recall,4),round(precision,4),round(f1_score,4),round(f2_score,4),round(brier,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Without days supply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = SAMPLE[['Gender', 'Age', 'Age_Gender', 'Num_presc',\n",
    "            'Avg_MME', 'Concurrent_opioid', 'Concurrent_benzo',\n",
    "            'Num_drug', 'Insurance_change', 'Codeine', 'Codeine_MME', 'Hydrocodone',\n",
    "            'Hydrocodone_MME', 'Oxycodone', 'Oxycodone_MME', 'Morphine',\n",
    "            'Morphine_MME', 'Hydromorphone', 'Hydromorphone_MME', 'Methadone',\n",
    "            'Methadone_MME', 'Fentanyl', 'Fentanyl_MME', 'Oxymorphone',\n",
    "            'Oxymorphone_MME', 'Medicaid', 'CommercialIns', 'Medicare',\n",
    "            'CashCredit', 'MilitaryIns', 'WorkersComp', 'Other', 'IndianNation',\n",
    "            'Change_Medicaid', 'Change_CommercialIns', 'Change_Medicare',\n",
    "            'Change_CashCredit', 'Change_MilitaryIns', 'Change_WorkersComp',\n",
    "            'Change_Other', 'Change_IndianNation']].values\n",
    "y = SAMPLE['Long_term_user'].values\n",
    "\n",
    "# Train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 42, stratify = y)\n",
    "clf_decision_tree = tree.DecisionTreeClassifier(max_depth = 5, random_state = 42, \n",
    "                                                class_weight='balanced', min_samples_leaf = 5,\n",
    "                                                min_impurity_decrease = 1e-5)\n",
    "clf_decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Decision tree\n",
    "fig, axe = plt.subplots(figsize=(40,10), dpi = 300)\n",
    "tree.plot_tree(clf_decision_tree, feature_names = ['Gender', 'Age', 'Age_Gender', 'Num_presc',\n",
    "                                                   'Avg_MME', 'Concurrent_opioid', 'Concurrent_benzo',\n",
    "                                                   'Num_drug', 'Insurance_change', 'Codeine', 'Codeine_MME', 'Hydrocodone',\n",
    "                                                   'Hydrocodone_MME', 'Oxycodone', 'Oxycodone_MME', 'Morphine',\n",
    "                                                   'Morphine_MME', 'Hydromorphone', 'Hydromorphone_MME', 'Methadone',\n",
    "                                                   'Methadone_MME', 'Fentanyl', 'Fentanyl_MME', 'Oxymorphone',\n",
    "                                                   'Oxymorphone_MME', 'Medicaid', 'CommercialIns', 'Medicare',\n",
    "                                                   'CashCredit', 'MilitaryIns', 'WorkersComp', 'Other', 'IndianNation',\n",
    "                                                   'Change_Medicaid', 'Change_CommercialIns', 'Change_Medicare',\n",
    "                                                   'Change_CashCredit', 'Change_MilitaryIns', 'Change_WorkersComp',\n",
    "                                                   'Change_Other', 'Change_IndianNation'], \\\n",
    "               class_names = ['short','long'], filled = True, rounded = True, ax = axe, fontsize=10)\n",
    "\n",
    "# fig.savefig('decisiontree_partial.png')\n",
    "\n",
    "# AUC\n",
    "y_pred_prob = clf_decision_tree.fit(X_train, y_train).predict_proba(X_test)[:,1]\n",
    "fpr, tpr, _ = metrics.roc_curve(y_test, y_pred_prob)\n",
    "p, r, _ = metrics.precision_recall_curve(y_test, y_pred_prob)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "pr_auc = metrics.auc(r, p)\n",
    "fig = plt.figure(figsize=(15,8))\n",
    "ax1 = fig.add_subplot(1,2,1)\n",
    "ax1.set_xlabel('Recall')\n",
    "ax1.set_ylabel('Precision')\n",
    "ax1.set_title('PR Curve')\n",
    "ax2 = fig.add_subplot(1,2,2)\n",
    "ax2.set_xlabel('False Positive Rate')\n",
    "ax2.set_ylabel('True Positive Rate')\n",
    "ax2.set_title('ROC Curve')\n",
    "ax1.plot(r, p, label=\"AUC =\" + str(round(pr_auc, 4)))\n",
    "ax2.plot(fpr, tpr, label=\"AUC =\" + str(round(roc_auc, 4)))\n",
    "ax1.legend(loc='upper right')    \n",
    "ax2.legend(loc='lower right')\n",
    "# fig.savefig('pr_roc_partial.png')\n",
    "\n",
    "# Others\n",
    "y_pred = clf_decision_tree.predict(X_test)\n",
    "accuracy = clf_decision_tree.score(X_test, y_test)\n",
    "recall = metrics.recall_score(y_test, y_pred)\n",
    "precision = metrics.precision_score(y_test, y_pred)\n",
    "f1_score = metrics.fbeta_score(y_test, y_pred, beta = 1)\n",
    "f2_score = metrics.fbeta_score(y_test, y_pred, beta = 2)\n",
    "brier = metrics.brier_score_loss(y_test, y_pred)\n",
    "print(round(accuracy,4),round(recall,4),round(precision,4),round(f1_score,4),round(f2_score,4),round(brier,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Models: \n",
    "- Decision Tree(CART), Explainable Boosting Machine (EBM)\n",
    "- L1/L2 Logistic, Linear SVM, Random Forest, XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import class_weight\n",
    "import utils.baseline_functions as base\n",
    "\n",
    "os.chdir('/Users/jingyuanhu/Desktop/Research/Interpretable_Opioid')\n",
    "SAMPLE = pd.read_csv('Data/PATIENT_TABLE.csv', delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = SAMPLE[['Gender', 'Age', 'Age_Gender', 'Num_presc',\n",
    "            'Total_days_supply', 'Avg_MME', 'Concurrent_opioid', 'Concurrent_benzo',\n",
    "            'Num_drug', 'Insurance_change', 'Codeine', 'Codeine_MME', 'Hydrocodone',\n",
    "            'Hydrocodone_MME', 'Oxycodone', 'Oxycodone_MME', 'Morphine',\n",
    "            'Morphine_MME', 'Hydromorphone', 'Hydromorphone_MME', 'Methadone',\n",
    "            'Methadone_MME', 'Fentanyl', 'Fentanyl_MME', 'Oxymorphone',\n",
    "            'Oxymorphone_MME', 'Medicaid', 'CommercialIns', 'Medicare',\n",
    "            'CashCredit', 'MilitaryIns', 'WorkersComp', 'Other', 'IndianNation',\n",
    "            'Change_Medicaid', 'Change_CommercialIns', 'Change_Medicare',\n",
    "            'Change_CashCredit', 'Change_MilitaryIns', 'Change_WorkersComp',\n",
    "            'Change_Other', 'Change_IndianNation']]\n",
    "y = SAMPLE['Long_term_user'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree: toy model to test different parameters\n",
    "depth = [1,2,3,4]\n",
    "min_samples = [5]\n",
    "impurity = [0.001,0.01,0.1]\n",
    "dt_summary = base.DecisionTree(X=x, Y=y, \n",
    "                               depth=depth, \n",
    "                               min_samples=min_samples, \n",
    "                               impurity=impurity,\n",
    "                               seed=42)\n",
    "dt_summary_balanced = base.DecisionTree(X=x, Y=y, \n",
    "                               depth=depth, \n",
    "                               min_samples=min_samples, \n",
    "                               impurity=impurity,\n",
    "                               class_weight=\"balanced\",\n",
    "                               seed=42)\n",
    "\n",
    "default = {\"Accuracy\": str(round(np.mean(dt_summary['holdout_test_accuracy']), 4)) + \" (\" + str(round(np.std(dt_summary['holdout_test_accuracy']), 4)) + \")\",\n",
    "           \"Recall\": str(round(np.mean(dt_summary['holdout_test_recall']), 4)) + \" (\" + str(round(np.std(dt_summary['holdout_test_recall']), 4)) + \")\",\n",
    "           \"Precision\": str(round(np.mean(dt_summary['holdout_test_precision']), 4)) + \" (\" + str(round(np.std(dt_summary['holdout_test_precision']), 4)) + \")\",\n",
    "           \"ROC AUC\": str(round(np.mean(dt_summary['holdout_test_roc_auc']), 4)) + \" (\" + str(round(np.std(dt_summary['holdout_test_roc_auc']), 4)) + \")\",\n",
    "           \"PR AUC\": str(round(np.mean(dt_summary['holdout_test_pr_auc']), 4)) + \" (\" + str(round(np.std(dt_summary['holdout_test_pr_auc']), 4)) + \")\",\n",
    "           \"Brier\": str(round(np.mean(dt_summary['holdout_test_brier']), 4)) + \" (\" + str(round(np.std(dt_summary['holdout_test_brier']), 4)) + \")\",\n",
    "           \"F2\": str(round(np.mean(dt_summary['holdout_test_f2']), 4)) + \" (\" + str(round(np.std(dt_summary['holdout_test_f2']), 4)) + \")\"}\n",
    "\n",
    "balanced = {\"Accuracy\": str(round(np.mean(dt_summary_balanced['holdout_test_accuracy']), 4)) + \" (\" + str(round(np.std(dt_summary_balanced['holdout_test_accuracy']), 4)) + \")\",\n",
    "           \"Recall\": str(round(np.mean(dt_summary_balanced['holdout_test_recall']), 4)) + \" (\" + str(round(np.std(dt_summary_balanced['holdout_test_recall']), 4)) + \")\",\n",
    "           \"Precision\": str(round(np.mean(dt_summary_balanced['holdout_test_precision']), 4)) + \" (\" + str(round(np.std(dt_summary_balanced['holdout_test_precision']), 4)) + \")\",\n",
    "           \"ROC AUC\": str(round(np.mean(dt_summary_balanced['holdout_test_roc_auc']), 4)) + \" (\" + str(round(np.std(dt_summary_balanced['holdout_test_roc_auc']), 4)) + \")\",\n",
    "           \"PR AUC\": str(round(np.mean(dt_summary_balanced['holdout_test_pr_auc']), 4)) + \" (\" + str(round(np.std(dt_summary_balanced['holdout_test_pr_auc']), 4)) + \")\",\n",
    "           \"Brier\": str(round(np.mean(dt_summary_balanced['holdout_test_brier']), 4)) + \" (\" + str(round(np.std(dt_summary_balanced['holdout_test_brier']), 4)) + \")\",\n",
    "           \"F2\": str(round(np.mean(dt_summary_balanced['holdout_test_f2']), 4)) + \" (\" + str(round(np.std(dt_summary_balanced['holdout_test_f2']), 4)) + \")\"}\n",
    "\n",
    "default = pd.DataFrame.from_dict(default, orient='index', columns=['Default'])\n",
    "balanced = pd.DataFrame.from_dict(balanced, orient='index', columns=['Balanced'])\n",
    "dt_results = pd.concat([default, balanced], axis=1)\n",
    "dt_results.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "depth = [1,2,3,4,5]\n",
    "min_samples = [5,10]\n",
    "impurity = [0.001,0.01,0.1]\n",
    "dt_summary = base.DecisionTree(X=x, Y=y, \n",
    "                               depth=depth, \n",
    "                               min_samples=min_samples, \n",
    "                               impurity=impurity,\n",
    "                               seed=42)\n",
    "dt_summary_balanced = base.DecisionTree(X=x, Y=y, \n",
    "                               depth=depth, \n",
    "                               min_samples=min_samples, \n",
    "                               impurity=impurity,\n",
    "                               class_weight=\"balanced\",\n",
    "                               seed=42)\n",
    "\n",
    "# EBM (parameters are changed)\n",
    "# max_leaves = [1,2,3]\n",
    "# min_samples = [1, 5, 10]\n",
    "# ebm_summary = base.EBM(X=x, Y=y,\n",
    "#                        max_leaves=max_leaves,\n",
    "#                        min_samples=min_samples,\n",
    "#                        seed=42)\n",
    "\n",
    "\n",
    "# L2 logistic\n",
    "c = np.linspace(1e-4,1,5).tolist()\n",
    "logistic_summary = base.Logistic(X=x, Y=y, C=c, seed=42)\n",
    "logistic_summary_balanced = base.Logistic(X=x, Y=y, C=c, class_weight=\"balanced\", seed=42)\n",
    "\n",
    "# L1 logistic\n",
    "c = np.linspace(1e-4,1,5).tolist()\n",
    "lasso_summary = base.Lasso(X=x, Y=y, C=c, seed=42)\n",
    "lasso_summary_balanced = base.Lasso(X=x, Y=y, C=c, class_weight=\"balanced\", seed=42)\n",
    "\n",
    "# LinearSVM\n",
    "c = np.linspace(1e-4,1,5).tolist()\n",
    "svm_summary = base.LinearSVM(X=x, Y=y, C=c, seed=42)\n",
    "svm_summary_balanced = base.LinearSVM(X=x, Y=y, C=c, class_weight=\"balanced\", seed=42)\n",
    "\n",
    "# Random Forest \n",
    "depth = [1,2,3,4,5]\n",
    "n_estimators = [50,100,200]\n",
    "impurity = [0.001,0.01]\n",
    "rf_summary = base.RF(X=x, Y=y,\n",
    "                     depth=depth,\n",
    "                     estimators=n_estimators,\n",
    "                     impurity=impurity,\n",
    "                     seed=42)\n",
    "rf_summary_balanced = base.RF(X=x, Y=y,\n",
    "                              depth=depth,\n",
    "                              estimators=n_estimators,\n",
    "                              impurity=impurity,\n",
    "                              class_weight=\"balanced\",\n",
    "                              seed=42)\n",
    "\n",
    "# XGBoost\n",
    "depth = [1,2,3,4,5]\n",
    "n_estimators =  [50,100]\n",
    "gamma = [5,10,15]\n",
    "child_weight = [5,10,15]\n",
    "xgb_summary = base.XGB(X=x, Y=y,\n",
    "                       depth=depth,\n",
    "                       estimators=n_estimators,\n",
    "                       gamma=gamma,\n",
    "                       child_weight=child_weight,\n",
    "                       seed=42)\n",
    "xgb_summary_balanced = base.XGB(X=x, Y=y,\n",
    "                                depth=depth,\n",
    "                                estimators=n_estimators,\n",
    "                                gamma=gamma,\n",
    "                                child_weight=child_weight,\n",
    "                                class_weight=\"balanced\",\n",
    "                                seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# DT\n",
    "default = {\"Accuracy\": str(round(np.mean(dt_summary['holdout_test_accuracy']), 4)) + \" (\" + str(round(np.std(dt_summary['holdout_test_accuracy']), 4)) + \")\",\n",
    "           \"Recall\": str(round(np.mean(dt_summary['holdout_test_recall']), 4)) + \" (\" + str(round(np.std(dt_summary['holdout_test_recall']), 4)) + \")\",\n",
    "           \"Precision\": str(round(np.mean(dt_summary['holdout_test_precision']), 4)) + \" (\" + str(round(np.std(dt_summary['holdout_test_precision']), 4)) + \")\",\n",
    "           \"ROC AUC\": str(round(np.mean(dt_summary['holdout_test_roc_auc']), 4)) + \" (\" + str(round(np.std(dt_summary['holdout_test_roc_auc']), 4)) + \")\",\n",
    "           \"PR AUC\": str(round(np.mean(dt_summary['holdout_test_pr_auc']), 4)) + \" (\" + str(round(np.std(dt_summary['holdout_test_pr_auc']), 4)) + \")\",\n",
    "           \"Brier\": str(round(np.mean(dt_summary['holdout_test_brier']), 4)) + \" (\" + str(round(np.std(dt_summary['holdout_test_brier']), 4)) + \")\",\n",
    "           \"F2\": str(round(np.mean(dt_summary['holdout_test_f2']), 4)) + \" (\" + str(round(np.std(dt_summary['holdout_test_f2']), 4)) + \")\"}\n",
    "\n",
    "balanced = {\"Accuracy\": str(round(np.mean(dt_summary_balanced['holdout_test_accuracy']), 4)) + \" (\" + str(round(np.std(dt_summary_balanced['holdout_test_accuracy']), 4)) + \")\",\n",
    "           \"Recall\": str(round(np.mean(dt_summary_balanced['holdout_test_recall']), 4)) + \" (\" + str(round(np.std(dt_summary_balanced['holdout_test_recall']), 4)) + \")\",\n",
    "           \"Precision\": str(round(np.mean(dt_summary_balanced['holdout_test_precision']), 4)) + \" (\" + str(round(np.std(dt_summary_balanced['holdout_test_precision']), 4)) + \")\",\n",
    "           \"ROC AUC\": str(round(np.mean(dt_summary_balanced['holdout_test_roc_auc']), 4)) + \" (\" + str(round(np.std(dt_summary_balanced['holdout_test_roc_auc']), 4)) + \")\",\n",
    "           \"PR AUC\": str(round(np.mean(dt_summary_balanced['holdout_test_pr_auc']), 4)) + \" (\" + str(round(np.std(dt_summary_balanced['holdout_test_pr_auc']), 4)) + \")\",\n",
    "           \"Brier\": str(round(np.mean(dt_summary_balanced['holdout_test_brier']), 4)) + \" (\" + str(round(np.std(dt_summary_balanced['holdout_test_brier']), 4)) + \")\",\n",
    "           \"F2\": str(round(np.mean(dt_summary_balanced['holdout_test_f2']), 4)) + \" (\" + str(round(np.std(dt_summary_balanced['holdout_test_f2']), 4)) + \")\"}\n",
    "\n",
    "default = pd.DataFrame.from_dict(default, orient='index', columns=['Decision Tree (Default)'])\n",
    "balanced = pd.DataFrame.from_dict(balanced, orient='index', columns=['Decision Tree (Balanced)'])\n",
    "dt_results = pd.concat([default, balanced], axis=1)\n",
    "\n",
    "# L2\n",
    "default = {\"Accuracy\": str(round(np.mean(logistic_summary['holdout_test_accuracy']), 4)) + \" (\" + str(round(np.std(logistic_summary['holdout_test_accuracy']), 4)) + \")\",\n",
    "           \"Recall\": str(round(np.mean(logistic_summary['holdout_test_recall']), 4)) + \" (\" + str(round(np.std(logistic_summary['holdout_test_recall']), 4)) + \")\",\n",
    "           \"Precision\": str(round(np.mean(logistic_summary['holdout_test_precision']), 4)) + \" (\" + str(round(np.std(logistic_summary['holdout_test_precision']), 4)) + \")\",\n",
    "           \"ROC AUC\": str(round(np.mean(logistic_summary['holdout_test_roc_auc']), 4)) + \" (\" + str(round(np.std(logistic_summary['holdout_test_roc_auc']), 4)) + \")\",\n",
    "           \"PR AUC\": str(round(np.mean(logistic_summary['holdout_test_pr_auc']), 4)) + \" (\" + str(round(np.std(logistic_summary['holdout_test_pr_auc']), 4)) + \")\",\n",
    "           \"Brier\": str(round(np.mean(logistic_summary['holdout_test_brier']), 4)) + \" (\" + str(round(np.std(logistic_summary['holdout_test_brier']), 4)) + \")\",\n",
    "           \"F2\": str(round(np.mean(logistic_summary['holdout_test_f2']), 4)) + \" (\" + str(round(np.std(logistic_summary['holdout_test_f2']), 4)) + \")\"}\n",
    "\n",
    "balanced = {\"Accuracy\": str(round(np.mean(logistic_summary_balanced['holdout_test_accuracy']), 4)) + \" (\" + str(round(np.std(logistic_summary_balanced['holdout_test_accuracy']), 4)) + \")\",\n",
    "           \"Recall\": str(round(np.mean(logistic_summary_balanced['holdout_test_recall']), 4)) + \" (\" + str(round(np.std(logistic_summary_balanced['holdout_test_recall']), 4)) + \")\",\n",
    "           \"Precision\": str(round(np.mean(logistic_summary_balanced['holdout_test_precision']), 4)) + \" (\" + str(round(np.std(logistic_summary_balanced['holdout_test_precision']), 4)) + \")\",\n",
    "           \"ROC AUC\": str(round(np.mean(logistic_summary_balanced['holdout_test_roc_auc']), 4)) + \" (\" + str(round(np.std(logistic_summary_balanced['holdout_test_roc_auc']), 4)) + \")\",\n",
    "           \"PR AUC\": str(round(np.mean(logistic_summary_balanced['holdout_test_pr_auc']), 4)) + \" (\" + str(round(np.std(logistic_summary_balanced['holdout_test_pr_auc']), 4)) + \")\",\n",
    "           \"Brier\": str(round(np.mean(logistic_summary_balanced['holdout_test_brier']), 4)) + \" (\" + str(round(np.std(logistic_summary_balanced['holdout_test_brier']), 4)) + \")\",\n",
    "           \"F2\": str(round(np.mean(logistic_summary_balanced['holdout_test_f2']), 4)) + \" (\" + str(round(np.std(logistic_summary_balanced['holdout_test_f2']), 4)) + \")\"}\n",
    "\n",
    "default = pd.DataFrame.from_dict(default, orient='index', columns=['Logistic (L2) (Default)'])\n",
    "balanced = pd.DataFrame.from_dict(balanced, orient='index', columns=['Logistic (L2) (Balanced)'])\n",
    "logistic_results = pd.concat([default, balanced], axis=1)\n",
    "\n",
    "\n",
    "# L1\n",
    "default = {\"Accuracy\": str(round(np.mean(lasso_summary['holdout_test_accuracy']), 4)) + \" (\" + str(round(np.std(lasso_summary['holdout_test_accuracy']), 4)) + \")\",\n",
    "           \"Recall\": str(round(np.mean(lasso_summary['holdout_test_recall']), 4)) + \" (\" + str(round(np.std(lasso_summary['holdout_test_recall']), 4)) + \")\",\n",
    "           \"Precision\": str(round(np.mean(lasso_summary['holdout_test_precision']), 4)) + \" (\" + str(round(np.std(lasso_summary['holdout_test_precision']), 4)) + \")\",\n",
    "           \"ROC AUC\": str(round(np.mean(lasso_summary['holdout_test_roc_auc']), 4)) + \" (\" + str(round(np.std(lasso_summary['holdout_test_roc_auc']), 4)) + \")\",\n",
    "           \"PR AUC\": str(round(np.mean(lasso_summary['holdout_test_pr_auc']), 4)) + \" (\" + str(round(np.std(lasso_summary['holdout_test_pr_auc']), 4)) + \")\",\n",
    "           \"Brier\": str(round(np.mean(lasso_summary['holdout_test_brier']), 4)) + \" (\" + str(round(np.std(lasso_summary['holdout_test_brier']), 4)) + \")\",\n",
    "           \"F2\": str(round(np.mean(lasso_summary['holdout_test_f2']), 4)) + \" (\" + str(round(np.std(lasso_summary['holdout_test_f2']), 4)) + \")\"}\n",
    "\n",
    "balanced = {\"Accuracy\": str(round(np.mean(lasso_summary_balanced['holdout_test_accuracy']), 4)) + \" (\" + str(round(np.std(lasso_summary_balanced['holdout_test_accuracy']), 4)) + \")\",\n",
    "           \"Recall\": str(round(np.mean(lasso_summary_balanced['holdout_test_recall']), 4)) + \" (\" + str(round(np.std(lasso_summary_balanced['holdout_test_recall']), 4)) + \")\",\n",
    "           \"Precision\": str(round(np.mean(lasso_summary_balanced['holdout_test_precision']), 4)) + \" (\" + str(round(np.std(lasso_summary_balanced['holdout_test_precision']), 4)) + \")\",\n",
    "           \"ROC AUC\": str(round(np.mean(lasso_summary_balanced['holdout_test_roc_auc']), 4)) + \" (\" + str(round(np.std(lasso_summary_balanced['holdout_test_roc_auc']), 4)) + \")\",\n",
    "           \"PR AUC\": str(round(np.mean(lasso_summary_balanced['holdout_test_pr_auc']), 4)) + \" (\" + str(round(np.std(lasso_summary_balanced['holdout_test_pr_auc']), 4)) + \")\",\n",
    "           \"Brier\": str(round(np.mean(lasso_summary_balanced['holdout_test_brier']), 4)) + \" (\" + str(round(np.std(lasso_summary_balanced['holdout_test_brier']), 4)) + \")\",\n",
    "           \"F2\": str(round(np.mean(lasso_summary_balanced['holdout_test_f2']), 4)) + \" (\" + str(round(np.std(lasso_summary_balanced['holdout_test_f2']), 4)) + \")\"}\n",
    "\n",
    "default = pd.DataFrame.from_dict(default, orient='index', columns=['Logistic (L1) (Default)'])\n",
    "balanced = pd.DataFrame.from_dict(balanced, orient='index', columns=['Logistic (L1) (Balanced)'])\n",
    "lasso_results = pd.concat([default, balanced], axis=1)\n",
    "\n",
    "\n",
    "# SVM\n",
    "default = {\"Accuracy\": str(round(np.mean(svm_summary['holdout_test_accuracy']), 4)) + \" (\" + str(round(np.std(svm_summary['holdout_test_accuracy']), 4)) + \")\",\n",
    "           \"Recall\": str(round(np.mean(svm_summary['holdout_test_recall']), 4)) + \" (\" + str(round(np.std(svm_summary['holdout_test_recall']), 4)) + \")\",\n",
    "           \"Precision\": str(round(np.mean(svm_summary['holdout_test_precision']), 4)) + \" (\" + str(round(np.std(svm_summary['holdout_test_precision']), 4)) + \")\",\n",
    "           \"ROC AUC\": str(round(np.mean(svm_summary['holdout_test_roc_auc']), 4)) + \" (\" + str(round(np.std(svm_summary['holdout_test_roc_auc']), 4)) + \")\",\n",
    "           \"PR AUC\": str(round(np.mean(svm_summary['holdout_test_pr_auc']), 4)) + \" (\" + str(round(np.std(svm_summary['holdout_test_pr_auc']), 4)) + \")\",\n",
    "           \"Brier\": str(round(np.mean(svm_summary['holdout_test_brier']), 4)) + \" (\" + str(round(np.std(svm_summary['holdout_test_brier']), 4)) + \")\",\n",
    "           \"F2\": str(round(np.mean(svm_summary['holdout_test_f2']), 4)) + \" (\" + str(round(np.std(svm_summary['holdout_test_f2']), 4)) + \")\"}\n",
    "\n",
    "balanced = {\"Accuracy\": str(round(np.mean(svm_summary_balanced['holdout_test_accuracy']), 4)) + \" (\" + str(round(np.std(svm_summary_balanced['holdout_test_accuracy']), 4)) + \")\",\n",
    "           \"Recall\": str(round(np.mean(svm_summary_balanced['holdout_test_recall']), 4)) + \" (\" + str(round(np.std(svm_summary_balanced['holdout_test_recall']), 4)) + \")\",\n",
    "           \"Precision\": str(round(np.mean(svm_summary_balanced['holdout_test_precision']), 4)) + \" (\" + str(round(np.std(svm_summary_balanced['holdout_test_precision']), 4)) + \")\",\n",
    "           \"ROC AUC\": str(round(np.mean(svm_summary_balanced['holdout_test_roc_auc']), 4)) + \" (\" + str(round(np.std(svm_summary_balanced['holdout_test_roc_auc']), 4)) + \")\",\n",
    "           \"PR AUC\": str(round(np.mean(svm_summary_balanced['holdout_test_pr_auc']), 4)) + \" (\" + str(round(np.std(svm_summary_balanced['holdout_test_pr_auc']), 4)) + \")\",\n",
    "           \"Brier\": str(round(np.mean(svm_summary_balanced['holdout_test_brier']), 4)) + \" (\" + str(round(np.std(svm_summary_balanced['holdout_test_brier']), 4)) + \")\",\n",
    "           \"F2\": str(round(np.mean(svm_summary_balanced['holdout_test_f2']), 4)) + \" (\" + str(round(np.std(svm_summary_balanced['holdout_test_f2']), 4)) + \")\"}\n",
    "\n",
    "default = pd.DataFrame.from_dict(default, orient='index', columns=['SVM (Default)'])\n",
    "balanced = pd.DataFrame.from_dict(balanced, orient='index', columns=['SVM (Balanced)'])\n",
    "svm_results = pd.concat([default, balanced], axis=1)\n",
    "\n",
    "\n",
    "# RF\n",
    "default = {\"Accuracy\": str(round(np.mean(rf_summary['holdout_test_accuracy']), 4)) + \" (\" + str(round(np.std(rf_summary['holdout_test_accuracy']), 4)) + \")\",\n",
    "           \"Recall\": str(round(np.mean(rf_summary['holdout_test_recall']), 4)) + \" (\" + str(round(np.std(rf_summary['holdout_test_recall']), 4)) + \")\",\n",
    "           \"Precision\": str(round(np.mean(rf_summary['holdout_test_precision']), 4)) + \" (\" + str(round(np.std(rf_summary['holdout_test_precision']), 4)) + \")\",\n",
    "           \"ROC AUC\": str(round(np.mean(rf_summary['holdout_test_roc_auc']), 4)) + \" (\" + str(round(np.std(rf_summary['holdout_test_roc_auc']), 4)) + \")\",\n",
    "           \"PR AUC\": str(round(np.mean(rf_summary['holdout_test_pr_auc']), 4)) + \" (\" + str(round(np.std(rf_summary['holdout_test_pr_auc']), 4)) + \")\",\n",
    "           \"Brier\": str(round(np.mean(rf_summary['holdout_test_brier']), 4)) + \" (\" + str(round(np.std(rf_summary['holdout_test_brier']), 4)) + \")\",\n",
    "           \"F2\": str(round(np.mean(rf_summary['holdout_test_f2']), 4)) + \" (\" + str(round(np.std(rf_summary['holdout_test_f2']), 4)) + \")\"}\n",
    "\n",
    "balanced = {\"Accuracy\": str(round(np.mean(rf_summary_balanced['holdout_test_accuracy']), 4)) + \" (\" + str(round(np.std(rf_summary_balanced['holdout_test_accuracy']), 4)) + \")\",\n",
    "           \"Recall\": str(round(np.mean(rf_summary_balanced['holdout_test_recall']), 4)) + \" (\" + str(round(np.std(rf_summary_balanced['holdout_test_recall']), 4)) + \")\",\n",
    "           \"Precision\": str(round(np.mean(rf_summary_balanced['holdout_test_precision']), 4)) + \" (\" + str(round(np.std(rf_summary_balanced['holdout_test_precision']), 4)) + \")\",\n",
    "           \"ROC AUC\": str(round(np.mean(rf_summary_balanced['holdout_test_roc_auc']), 4)) + \" (\" + str(round(np.std(rf_summary_balanced['holdout_test_roc_auc']), 4)) + \")\",\n",
    "           \"PR AUC\": str(round(np.mean(rf_summary_balanced['holdout_test_pr_auc']), 4)) + \" (\" + str(round(np.std(rf_summary_balanced['holdout_test_pr_auc']), 4)) + \")\",\n",
    "           \"Brier\": str(round(np.mean(rf_summary_balanced['holdout_test_brier']), 4)) + \" (\" + str(round(np.std(rf_summary_balanced['holdout_test_brier']), 4)) + \")\",\n",
    "           \"F2\": str(round(np.mean(rf_summary_balanced['holdout_test_f2']), 4)) + \" (\" + str(round(np.std(rf_summary_balanced['holdout_test_f2']), 4)) + \")\"}\n",
    "\n",
    "default = pd.DataFrame.from_dict(default, orient='index', columns=['Random Forest (Default)'])\n",
    "balanced = pd.DataFrame.from_dict(balanced, orient='index', columns=['Random Forest (Balanced)'])\n",
    "rf_results = pd.concat([default, balanced], axis=1)\n",
    "\n",
    "\n",
    "# XGB\n",
    "default = {\"Accuracy\": str(round(np.mean(xgb_summary['holdout_test_accuracy']), 4)) + \" (\" + str(round(np.std(xgb_summary['holdout_test_accuracy']), 4)) + \")\",\n",
    "           \"Recall\": str(round(np.mean(xgb_summary['holdout_test_recall']), 4)) + \" (\" + str(round(np.std(xgb_summary['holdout_test_recall']), 4)) + \")\",\n",
    "           \"Precision\": str(round(np.mean(xgb_summary['holdout_test_precision']), 4)) + \" (\" + str(round(np.std(xgb_summary['holdout_test_precision']), 4)) + \")\",\n",
    "           \"ROC AUC\": str(round(np.mean(xgb_summary['holdout_test_roc_auc']), 4)) + \" (\" + str(round(np.std(xgb_summary['holdout_test_roc_auc']), 4)) + \")\",\n",
    "           \"PR AUC\": str(round(np.mean(xgb_summary['holdout_test_pr_auc']), 4)) + \" (\" + str(round(np.std(xgb_summary['holdout_test_pr_auc']), 4)) + \")\",\n",
    "           \"Brier\": str(round(np.mean(xgb_summary['holdout_test_brier']), 4)) + \" (\" + str(round(np.std(xgb_summary['holdout_test_brier']), 4)) + \")\",\n",
    "           \"F2\": str(round(np.mean(xgb_summary['holdout_test_f2']), 4)) + \" (\" + str(round(np.std(xgb_summary['holdout_test_f2']), 4)) + \")\"}\n",
    "\n",
    "balanced = {\"Accuracy\": str(round(np.mean(xgb_summary_balanced['holdout_test_accuracy']), 4)) + \" (\" + str(round(np.std(xgb_summary_balanced['holdout_test_accuracy']), 4)) + \")\",\n",
    "           \"Recall\": str(round(np.mean(xgb_summary_balanced['holdout_test_recall']), 4)) + \" (\" + str(round(np.std(xgb_summary_balanced['holdout_test_recall']), 4)) + \")\",\n",
    "           \"Precision\": str(round(np.mean(xgb_summary_balanced['holdout_test_precision']), 4)) + \" (\" + str(round(np.std(xgb_summary_balanced['holdout_test_precision']), 4)) + \")\",\n",
    "           \"ROC AUC\": str(round(np.mean(xgb_summary_balanced['holdout_test_roc_auc']), 4)) + \" (\" + str(round(np.std(xgb_summary_balanced['holdout_test_roc_auc']), 4)) + \")\",\n",
    "           \"PR AUC\": str(round(np.mean(xgb_summary_balanced['holdout_test_pr_auc']), 4)) + \" (\" + str(round(np.std(xgb_summary_balanced['holdout_test_pr_auc']), 4)) + \")\",\n",
    "           \"Brier\": str(round(np.mean(xgb_summary_balanced['holdout_test_brier']), 4)) + \" (\" + str(round(np.std(xgb_summary_balanced['holdout_test_brier']), 4)) + \")\",\n",
    "           \"F2\": str(round(np.mean(xgb_summary_balanced['holdout_test_f2']), 4)) + \" (\" + str(round(np.std(xgb_summary_balanced['holdout_test_f2']), 4)) + \")\"}\n",
    "\n",
    "default = pd.DataFrame.from_dict(default, orient='index', columns=['XGB (Default)'])\n",
    "balanced = pd.DataFrame.from_dict(balanced, orient='index', columns=['XGB (Balanced)'])\n",
    "xgb_results = pd.concat([default, balanced], axis=1)\n",
    "\n",
    "\n",
    "results = pd.concat([dt_results, logistic_results], axis=1)\n",
    "results = pd.concat([results, lasso_results], axis=1)\n",
    "results = pd.concat([results, svm_results], axis=1)\n",
    "results = pd.concat([results, rf_results], axis=1)\n",
    "results = pd.concat([results, xgb_results], axis=1)\n",
    "results = results.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results\n",
    "path = './Results/baselines/'\n",
    "results.to_csv(path + \"results.csv\")\n",
    "\n",
    "# results_param = {\"Decision Tree\": dt_summary['best_param'],\n",
    "#  \"Explainable Boosting Machine\": ebm_summary['best_param'],\n",
    "#  \"Logistic (L2)\": logistic_summary['best_param'],\n",
    "#  \"Logistic (L1)\": lasso_summary['best_param'],\n",
    "#  \"Linear SVM\": svm_summary['best_param'],\n",
    "#  \"Random Forest\": rf_summary['best_param'],\n",
    "#  \"XG Boost\": xgb_summary['best_param']}\n",
    "# results_param = pd.DataFrame.from_dict(results_param, orient='index')\n",
    "# results_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additive stumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import class_weight\n",
    "import utils.stumps as stumps\n",
    "import time\n",
    "\n",
    "os.chdir('/Users/jingyuanhu/Desktop/Research/Interpretable Opioid')\n",
    "SAMPLE = pd.read_csv('Data/PATIENT_TABLE.csv', delimiter = \",\")\n",
    "\n",
    "x = SAMPLE[['Gender', 'Age', 'Age_Gender',\n",
    "            'Num_presc', 'Total_days_supply','Concurrent_opioid', 'Concurrent_benzo',\n",
    "            'Num_drug', 'Insurance_change', 'Codeine', 'Codeine_MME', 'Hydrocodone',\n",
    "            'Hydrocodone_MME', 'Oxycodone', 'Oxycodone_MME', 'Morphine', 'Morphine_MME', \n",
    "            'Hydromorphone','Hydromorphone_MME', 'Methadone', 'Methadone_MME', 'Fentanyl',\n",
    "            'Fentanyl_MME', 'Oxymorphone', 'Oxymorphone_MME', 'Medicaid',\n",
    "            'CommercialIns', 'Medicare', 'CashCredit', 'MilitaryIns', 'WorkersComp',\n",
    "            'Other', 'IndianNation', 'Medicaid_CommercialIns', 'Medicaid_Medicare',\n",
    "            'Medicaid_CashCredit', 'Medicaid_MilitaryIns', 'Medicaid_WorkersComp',\n",
    "            'Medicaid_Other', 'Medicaid_IndianNation', 'CommercialIns_Medicaid',\n",
    "            'CommercialIns_Medicare', 'CommercialIns_CashCredit',\n",
    "            'CommercialIns_MilitaryIns', 'CommercialIns_WorkersComp',\n",
    "            'CommercialIns_Other', 'CommercialIns_IndianNation',\n",
    "            'Medicare_Medicaid', 'Medicare_CommercialIns', 'Medicare_CashCredit',\n",
    "            'Medicare_MilitaryIns', 'Medicare_WorkersComp', 'Medicare_Other',\n",
    "            'Medicare_IndianNation', 'CashCredit_Medicaid',\n",
    "            'CashCredit_CommercialIns', 'CashCredit_Medicare',\n",
    "            'CashCredit_MilitaryIns', 'CashCredit_WorkersComp', 'CashCredit_Other',\n",
    "            'CashCredit_IndianNation', 'MilitaryIns_Medicaid',\n",
    "            'MilitaryIns_CommercialIns', 'MilitaryIns_Medicare',\n",
    "            'MilitaryIns_CashCredit', 'MilitaryIns_WorkersComp',\n",
    "            'MilitaryIns_Other', 'MilitaryIns_IndianNation', 'WorkersComp_Medicaid',\n",
    "            'WorkersComp_CommercialIns', 'WorkersComp_Medicare',\n",
    "            'WorkersComp_CashCredit', 'WorkersComp_MilitaryIns',\n",
    "            'WorkersComp_Other', 'WorkersComp_IndianNation', 'Other_Medicaid',\n",
    "            'Other_CommercialIns', 'Other_Medicare', 'Other_CashCredit',\n",
    "            'Other_MilitaryIns', 'Other_WorkersComp', 'Other_IndianNation',\n",
    "            'IndianNation_Medicaid', 'IndianNation_CommercialIns',\n",
    "            'IndianNation_Medicare', 'IndianNation_CashCredit',\n",
    "            'IndianNation_MilitaryIns', 'IndianNation_WorkersComp',\n",
    "            'IndianNation_Other']]\n",
    "\n",
    "# x = SAMPLE[['Gender', 'Age', 'Age_Gender', 'Num_presc',\n",
    "#             'Total_days_supply', 'Avg_MME', 'Concurrent_opioid', 'Concurrent_benzo',\n",
    "#             'Num_drug', 'Insurance_change', 'Codeine', 'Codeine_MME', 'Hydrocodone',\n",
    "#             'Hydrocodone_MME', 'Oxycodone', 'Oxycodone_MME', 'Morphine',\n",
    "#             'Morphine_MME', 'Hydromorphone', 'Hydromorphone_MME', 'Methadone',\n",
    "#             'Methadone_MME', 'Fentanyl', 'Fentanyl_MME', 'Oxymorphone',\n",
    "#             'Oxymorphone_MME', 'Medicaid', 'CommercialIns', 'Medicare',\n",
    "#             'CashCredit', 'MilitaryIns', 'WorkersComp', 'Other', 'IndianNation',\n",
    "#             'Change_Medicaid', 'Change_CommercialIns', 'Change_Medicare',\n",
    "#             'Change_CashCredit', 'Change_MilitaryIns', 'Change_WorkersComp',\n",
    "#             'Change_Other', 'Change_IndianNation']]\n",
    "\n",
    "y = SAMPLE['Long_term_user'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COMPLETE STUMPS: cutoffs at all possible value\n",
    "\n",
    "### Only need to be run once\n",
    "# list of lists, each sublist contains all possible value of a feature\n",
    "\n",
    "# cutoffs = []\n",
    "# for column_name in x.columns:\n",
    "#     # one cutoff for binary variables\n",
    "#     if (len(x[column_name].unique()) == 2):\n",
    "#         cutoffs.append([sorted(x[column_name].unique())[1]])\n",
    "#     else:\n",
    "#         cutoffs.append(sorted(x[column_name].unique()))\n",
    "\n",
    "# new_data = stumps.create_stumps(x.values, x.columns, cutoffs)\n",
    "# new_data.to_csv('Data/STUMPS.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.linspace(min(x['IndianNation_WorkersComp'].unique()), \n",
    "#             max(x['IndianNation_WorkersComp'].unique()), \n",
    "#             num = 3+1,\n",
    "#             endpoint = False)[1:,].astype(int).tolist()\n",
    "\n",
    "# sorted(x['IndianNation_MilitaryIns'].unique())\n",
    "# len(x['IndianNation_MilitaryIns'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### SMART STUMPS: instead of creating stumps for every possible value\n",
    "\n",
    "### drop columns with only one value, no need to create stumps\n",
    "columns_to_drop = []\n",
    "for column_name in x.columns:\n",
    "    if (len(x[column_name].unique()) == 1):\n",
    "        columns_to_drop.append(column_name)\n",
    "        \n",
    "x = x.drop(columns=columns_to_drop)\n",
    "\n",
    "### cutoffs equally selected\n",
    "num_cutoff = 3\n",
    "cutoffs = []\n",
    "\n",
    "for column_name in x.columns:\n",
    "    # one cutoff for binary variables\n",
    "    if (len(x[column_name].unique()) == 2):\n",
    "        cutoffs.append([sorted(x[column_name].unique())[1]])\n",
    "    elif (len(x[column_name].unique()) == 3):\n",
    "        cutoffs.append([sorted(x[column_name].unique())[2]])\n",
    "    # at least four unique values\n",
    "    else:\n",
    "        cutoffs.append(np.linspace(min(x[column_name].unique()), \n",
    "                                   max(x[column_name].unique()), \n",
    "                                   num = num_cutoff+1,\n",
    "                                   endpoint = False)[1:,].astype(int).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create stumps\n",
    "new_data = stumps.create_stumps(x.values, x.columns, cutoffs)\n",
    "new_data.to_csv('Data/SMART_STUMPS.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additive stumps\n",
    "start = time.time()\n",
    "stump_summary = stumps.stump_cv(X = STUMPS, \n",
    "                                Y = y, \n",
    "                                columns=STUMPS.columns, \n",
    "                                c_grid={'C': np.linspace(1e-4,1e-1,10).tolist()},\n",
    "                                seed = 42)\n",
    "end = time.time()\n",
    "print(str(round(end - start,1)) + ' seconds (default)')\n",
    "\n",
    "start = time.time()\n",
    "stump_summary_balanced = stumps.stump_cv(X = STUMPS, \n",
    "                                Y = y, \n",
    "                                columns=STUMPS.columns, \n",
    "                                c_grid={'C': np.linspace(1e-4,1e-1,10).tolist()},\n",
    "                                class_weight = 'balanced',\n",
    "                                seed = 42)\n",
    "end = time.time()\n",
    "print(str(round(end - start,1)) + ' seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default = {\"Accuracy\": str(round(np.mean(stump_summary['holdout_test_accuracy']), 4)) + \" (\" + str(round(np.std(stump_summary['holdout_test_accuracy']), 4)) + \")\",\n",
    "           \"Recall\": str(round(np.mean(stump_summary['holdout_test_recall']), 4)) + \" (\" + str(round(np.std(stump_summary['holdout_test_recall']), 4)) + \")\",\n",
    "           \"Precision\": str(round(np.mean(stump_summary['holdout_test_precision']), 4)) + \" (\" + str(round(np.std(stump_summary['holdout_test_precision']), 4)) + \")\",\n",
    "           \"ROC AUC\": str(round(np.mean(stump_summary['holdout_test_roc_auc']), 4)) + \" (\" + str(round(np.std(stump_summary['holdout_test_roc_auc']), 4)) + \")\",\n",
    "           \"PR AUC\": str(round(np.mean(stump_summary['holdout_test_pr_auc']), 4)) + \" (\" + str(round(np.std(stump_summary['holdout_test_pr_auc']), 4)) + \")\",\n",
    "           \"Brier\": str(round(np.mean(stump_summary['holdout_test_brier']), 4)) + \" (\" + str(round(np.std(stump_summary['holdout_test_brier']), 4)) + \")\",\n",
    "           \"F2\": str(round(np.mean(stump_summary['holdout_test_f2']), 4)) + \" (\" + str(round(np.std(stump_summary['holdout_test_f2']), 4)) + \")\"}\n",
    "\n",
    "balanced = {\"Accuracy\": str(round(np.mean(stump_summary_balanced['holdout_test_accuracy']), 4)) + \" (\" + str(round(np.std(stump_summary_balanced['holdout_test_accuracy']), 4)) + \")\",\n",
    "           \"Recall\": str(round(np.mean(stump_summary_balanced['holdout_test_recall']), 4)) + \" (\" + str(round(np.std(stump_summary_balanced['holdout_test_recall']), 4)) + \")\",\n",
    "           \"Precision\": str(round(np.mean(stump_summary_balanced['holdout_test_precision']), 4)) + \" (\" + str(round(np.std(stump_summary_balanced['holdout_test_precision']), 4)) + \")\",\n",
    "           \"ROC AUC\": str(round(np.mean(stump_summary_balanced['holdout_test_roc_auc']), 4)) + \" (\" + str(round(np.std(stump_summary_balanced['holdout_test_roc_auc']), 4)) + \")\",\n",
    "           \"PR AUC\": str(round(np.mean(stump_summary_balanced['holdout_test_pr_auc']), 4)) + \" (\" + str(round(np.std(stump_summary_balanced['holdout_test_pr_auc']), 4)) + \")\",\n",
    "           \"Brier\": str(round(np.mean(stump_summary_balanced['holdout_test_brier']), 4)) + \" (\" + str(round(np.std(stump_summary_balanced['holdout_test_brier']), 4)) + \")\",\n",
    "           \"F2\": str(round(np.mean(stump_summary_balanced['holdout_test_f2']), 4)) + \" (\" + str(round(np.std(stump_summary_balanced['holdout_test_f2']), 4)) + \")\"}\n",
    "\n",
    "default = pd.DataFrame.from_dict(default, orient='index', columns=['Additive Stumps (Default, Resample)'])\n",
    "balanced = pd.DataFrame.from_dict(balanced, orient='index', columns=['Additive Stumps (Balanced, Resample)'])\n",
    "stump_results = pd.concat([default, balanced], axis=1)\n",
    "stump_results.T\n",
    "# stump_results.to_csv('stump_results.csv', header=True, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stump_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stump_normal = pd.read_csv('stump_results.csv', delimiter = \",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RiskSlim\n",
    "Because it is more time consuming, all the experiments are run on a sample dataset of size 400 (200 patient each class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, precision_score, roc_auc_score,\\\n",
    "average_precision_score, brier_score_loss, fbeta_score, accuracy_score\n",
    "\n",
    "import pprint\n",
    "import riskslim\n",
    "import utils.RiskSLIM as slim\n",
    "from riskslim.utils import print_model\n",
    "\n",
    "os.chdir('/Users/jingyuanhu/Desktop/Research/Interpretable Opioid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocessing data\n",
    "\n",
    "### Load stumps data\n",
    "STUMPS = pd.read_csv('Data/SMART_STUMPS.csv', delimiter = \",\")\n",
    "SAMPLE_PATIENT = pd.read_csv('Data/SAMPLE_PATIENT_DATA.csv', delimiter = \",\")\n",
    "\n",
    "STUMPS['(Intercept)'] = 1\n",
    "intercept = STUMPS.pop('(Intercept)')\n",
    "STUMPS.insert(0, '(Intercept)', intercept)\n",
    "\n",
    "# STUMPS.columns = ['(Intercept)', *STUMPS.columns[1:]]\n",
    "x, y = STUMPS, SAMPLE_PATIENT.to_numpy()[:,[0]]\n",
    "y[y==0]= -1\n",
    "\n",
    "# STUMPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Risk SLIM\n",
    "\n",
    "# Training & testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1, random_state = 25, stratify = y)\n",
    "\n",
    "# problem parameters\n",
    "max_coefficient = 5                                         # value of largest/smallest coefficient\n",
    "max_L0_value = 5                                            # maximum model size\n",
    "max_offset = 50                                             # maximum value of offset parameter (optional)\n",
    "c0_value = 1e-6                                             # L0-penalty parameter such that c0_value > 0; larger values -> sparser models; we set to a small value (1e-6) so that we get a model with max_L0_value terms\n",
    "w_pos = 1.00                                                # relative weight on examples with y = +1; w_neg = 1.00 (optional)\n",
    "w_pos = len(y_train) / sum(y_train==1)[0]                   # balanced weight based on ratio\n",
    "\n",
    "# load dataset\n",
    "data = {\n",
    "    'X': x_train.values,\n",
    "    'Y': y_train,\n",
    "    'variable_names': x_train.columns.tolist(),\n",
    "    'outcome_name': 'Long_term_user',\n",
    "    'sample_weights': np.repeat(1, len(y_train))\n",
    "}\n",
    "\n",
    "# coefficient set\n",
    "coef_set = riskslim.CoefficientSet(variable_names = data['variable_names'], lb=-max_coefficient, ub=max_coefficient,\n",
    "                                   sign=0)\n",
    "coef_set.update_intercept_bounds(X = data['X'], y = data['Y'], max_offset = max_offset)\n",
    "\n",
    "# create constraint dictionary\n",
    "N, P = data['X'].shape\n",
    "trivial_L0_max = P - np.sum(coef_set.C_0j == 0)\n",
    "max_L0_value = min(max_L0_value, trivial_L0_max)\n",
    "\n",
    "# run model\n",
    "model_info, mip_info, lcpa_info = slim.risk_slim_constrain(data, \n",
    "                                                           max_coefficient=5, \n",
    "                                                           max_L0_value=5, \n",
    "                                                           c0_value=1e-6, \n",
    "                                                           max_offset=100, \n",
    "                                                           max_runtime=1000,\n",
    "                                                           w_pos = w_pos)\n",
    "print_model(model_info['solution'], data)\n",
    "# pprint.pprint(model_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Risk SLIM (single) performance metric\n",
    "y_test[y_test == -1] = 0\n",
    "\n",
    "test_prob = slim.riskslim_prediction(x_test.values, np.array(x_test.columns.tolist()), model_info)\n",
    "test_pred = (test_prob > 0.5)\n",
    "\n",
    "accuracy = accuracy_score(y_test, test_pred)\n",
    "recall = recall_score(y_test, test_pred)\n",
    "roc_auc = roc_auc_score(y_test, test_prob)\n",
    "pr_auc = average_precision_score(y_test, test_prob)\n",
    "\n",
    "print(accuracy, recall, roc_auc, pr_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Risk SLIM (nested CV)\n",
    "### Only tune one hyperparameter for computational issues and to control variations\n",
    "### has to equal the num_folds of inner_CV\n",
    "max_coef_number = [1,2,3,4,5]\n",
    "\n",
    "risk_summary = slim.risk_nested_cv_constrain(X=x, \n",
    "                                             Y=y,\n",
    "                                             y_label='Long_term_user', \n",
    "                                             max_coef=5, \n",
    "                                             max_coef_number=max_coef_number,\n",
    "                                             c=1e-6, \n",
    "                                             seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_coef_number = [1,2,3,4,5]\n",
    "\n",
    "risk_summary_balanced = slim.risk_nested_cv_constrain(X=x,\n",
    "                                                      Y=y,\n",
    "                                                      y_label='Long_term_user', \n",
    "                                                      max_coef=5, \n",
    "                                                      max_coef_number=max_coef_number,\n",
    "                                                      c=1e-6, \n",
    "                                                      class_weight='balanced',\n",
    "                                                      seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default = {\"Accuracy\": str(round(np.mean(risk_summary['holdout_test_accuracy']), 4)) + \" (\" + str(round(np.std(risk_summary['holdout_test_accuracy']), 4)) + \")\",\n",
    "           \"Recall\": str(round(np.mean(risk_summary['holdout_test_recall']), 4)) + \" (\" + str(round(np.std(risk_summary['holdout_test_recall']), 4)) + \")\",\n",
    "           \"Precision\": str(round(np.mean(risk_summary['holdout_test_precision']), 4)) + \" (\" + str(round(np.std(risk_summary['holdout_test_precision']), 4)) + \")\",\n",
    "           \"ROC AUC\": str(round(np.mean(risk_summary['holdout_test_roc_auc']), 4)) + \" (\" + str(round(np.std(risk_summary['holdout_test_roc_auc']), 4)) + \")\",\n",
    "           \"PR AUC\": str(round(np.mean(risk_summary['holdout_test_pr_auc']), 4)) + \" (\" + str(round(np.std(risk_summary['holdout_test_pr_auc']), 4)) + \")\",\n",
    "           \"Brier\": str(round(np.mean(risk_summary['holdout_test_brier']), 4)) + \" (\" + str(round(np.std(risk_summary['holdout_test_brier']), 4)) + \")\",\n",
    "           \"F2\": str(round(np.mean(risk_summary['holdout_test_f2']), 4)) + \" (\" + str(round(np.std(risk_summary['holdout_test_f2']), 4)) + \")\"}\n",
    "\n",
    "balanced = {\"Accuracy\": str(round(np.mean(risk_summary_balanced['holdout_test_accuracy']), 4)) + \" (\" + str(round(np.std(risk_summary_balanced['holdout_test_accuracy']), 4)) + \")\",\n",
    "           \"Recall\": str(round(np.mean(risk_summary_balanced['holdout_test_recall']), 4)) + \" (\" + str(round(np.std(risk_summary_balanced['holdout_test_recall']), 4)) + \")\",\n",
    "           \"Precision\": str(round(np.mean(risk_summary_balanced['holdout_test_precision']), 4)) + \" (\" + str(round(np.std(risk_summary_balanced['holdout_test_precision']), 4)) + \")\",\n",
    "           \"ROC AUC\": str(round(np.mean(risk_summary_balanced['holdout_test_roc_auc']), 4)) + \" (\" + str(round(np.std(risk_summary_balanced['holdout_test_roc_auc']), 4)) + \")\",\n",
    "           \"PR AUC\": str(round(np.mean(risk_summary_balanced['holdout_test_pr_auc']), 4)) + \" (\" + str(round(np.std(risk_summary_balanced['holdout_test_pr_auc']), 4)) + \")\",\n",
    "           \"Brier\": str(round(np.mean(risk_summary_balanced['holdout_test_brier']), 4)) + \" (\" + str(round(np.std(risk_summary_balanced['holdout_test_brier']), 4)) + \")\",\n",
    "           \"F2\": str(round(np.mean(risk_summary_balanced['holdout_test_f2']), 4)) + \" (\" + str(round(np.std(risk_summary_balanced['holdout_test_f2']), 4)) + \")\"}\n",
    "\n",
    "\n",
    "default = pd.DataFrame.from_dict(default, orient='index', columns=['Risk SLIM (Default)'])\n",
    "balanced = pd.DataFrame.from_dict(balanced, orient='index', columns=['Risk SLIM (Balanced)'])\n",
    "slim_results = pd.concat([default, balanced], axis=1)\n",
    "slim_results.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
